{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject  üëÅÔ∏è Image Recognition multiclass classification Landscapes  \n",
    "##  üè¢üå≤üßä‚õ∞Ô∏èüåäüèôÔ∏è\n",
    "### Wesley, Keven, Didier, Celso  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data üì¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from pathlib import Path\n",
    "import os\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from keras.preprocessing import image\n",
    "# Load data set x contains the actual images in 32 x 32  \n",
    "# composed of 32x32 images with 3 color channels \n",
    "# mnist = keras.datasets.fashion_mnist\n",
    "# img = image.load_img(\"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/Data/seg_train/buildings/0.jpg\", target_size=(28, 28),color_mode=\"grayscale\")\n",
    " \n",
    "image_size = (40,40)\n",
    "\n",
    "class_labels = [\n",
    "    \"buildings\",\n",
    "     \"forest\",\n",
    "     \"glacier\",\n",
    "     \"mountain\",\n",
    "     \"sea\",\n",
    "     \"street\"\n",
    "]\n",
    "\n",
    "data_path = \"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/Data/seg_\"\n",
    "\n",
    "x_train = np.ndarray((0,30,30)) \n",
    "x_test = np.ndarray((0,30,30)) \n",
    "\n",
    "def make_Y(TypeOfSet):\n",
    "    path=data_path+TypeOfSet\n",
    "    Data_dir_content = os.listdir(path)\n",
    "    resulting_y = []\n",
    "\n",
    "    for label in Data_dir_content:\n",
    "        label_dir_content = os.listdir(path+f\"/{label}\")\n",
    "\n",
    "        for _ in range(len(label_dir_content)):\n",
    "            resulting_y.append(class_labels.index(label))\n",
    "\n",
    "    return resulting_y\n",
    "\n",
    "def make_X(TypeOfSet):\n",
    "    path=data_path+TypeOfSet\n",
    "    Data_dir_content = os.listdir(path)\n",
    "    resulting_X = np.ndarray((0,30,30))\n",
    "\n",
    "    for label in Data_dir_content:\n",
    "        label_dir_path=path+f\"/{label}\"\n",
    "        label_dir_content = os.listdir(label_dir_path)\n",
    "\n",
    "        for element in label_dir_content:\n",
    "           processed_img = prepare_img_for_model(label_dir_path+f\"/{element}\")\n",
    "           resulting_X = np.append(resulting_X,processed_img,axis=0)\n",
    "\n",
    "    return resulting_X\n",
    "\n",
    "def prepare_img_for_model(path):\n",
    "    img = image.load_img(path,target_size=(30,30),color_mode=\"grayscale\")\n",
    "    image_as_array = image.img_to_array(img)\n",
    "    image_reshaped = image_as_array.reshape(30,30)\n",
    "    return np.expand_dims( image_reshaped, axis=0)\n",
    "\n",
    "x_test = make_X(\"test\")\n",
    "x_train =make_X(\"train\")\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "y_train = make_Y(\"train\")\n",
    "y_test = make_Y(\"test\")\n",
    "\n",
    "y_train = to_categorical(y_train, 6)\n",
    "y_test = to_categorical(y_test, 6)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv2D_1 (Conv2D)           (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " Conv2D_2 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " Conv2D_3 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " Conv2D_4 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " DenseLayer_1 (Dense)        (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,248,230\n",
      "Trainable params: 1,248,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 2D convolutional layers for images 1D can fit for other kind like Sound\n",
    "# Params:\n",
    "# 1 filters :how many differnet filters should be in the layer, one filter by pattern\n",
    "# 2 kernel_size : size of the window used when creating the tiles for each image\n",
    "# 3 padding: in case the kernel size doesnt match the corner ignore or fill with 0\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\",activation='relu', input_shape=(30,30,1),name=\"Conv2D_1\"))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3),activation='relu', name=\"Conv2D_2\"))\n",
    "\n",
    "#max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Dropout, randomly cut connections, normally used between [25-50]%\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),padding=\"same\", activation='relu', name=\"Conv2D_3\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),activation='relu',name=\"Conv2D_4\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#To transition from Convolutional layers to Dense layers we need to tell karas that we no longer want to use 2D data\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu', name=\"DenseLayer_1\"))\n",
    "model.add(Dropout(0.5))\n",
    "# when doing classificaton with more than one kind of object we almost always use softmax activator for the output\n",
    "model.add(Dense(6, activation=\"softmax\", name=\"output_layer\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "585/585 [==============================] - 21s 35ms/step - loss: 1.2053 - accuracy: 0.5076 - val_loss: 1.0158 - val_accuracy: 0.6080\n",
      "Epoch 2/3\n",
      "  1/585 [..............................] - ETA: 17s - loss: 0.8206 - accuracy: 0.7083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:48:13.733164: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 283115520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 22s 37ms/step - loss: 0.9254 - accuracy: 0.6442 - val_loss: 0.8195 - val_accuracy: 0.6783\n",
      "Epoch 3/3\n",
      "585/585 [==============================] - 22s 38ms/step - loss: 0.7896 - accuracy: 0.7037 - val_loss: 0.7308 - val_accuracy: 0.7270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe196bf62f0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size is how many images we want to fit in to the network at once during the training,\n",
    "# too low it takes too long to train, to high we will run out of memory. typical [32-128]\n",
    "# tensorboard --logdir=/home/celso/Documents/DeepLearning/ImageClassification/MNIST_fashion/logs\n",
    "FirstRun = \"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/logs/FirstRun\"\n",
    "# PARAMS: \n",
    "# image 30 x 30 x 1 \n",
    "# batch_size=24,\n",
    "# epochs=3,\n",
    "\n",
    "\n",
    "SecondRun = \"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/logs/SecondRun\"\n",
    "logger =  keras.callbacks.TensorBoard(\n",
    "    log_dir=FirstRun,\n",
    "    # log_dir=SecondRun,\n",
    "    write_graph=True, #log the structure of the model\n",
    "    histogram_freq =5 #how each layer is working (for every 5 passes of the training data)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=24,\n",
    "    epochs=3,\n",
    "    validation_data=(x_test, y_test),\n",
    "    shuffle=True,\n",
    "    callbacks=[logger]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) for the test data set is: [0.7308340668678284, 0.7269999980926514]\n"
     ]
    }
   ],
   "source": [
    "test_error_rate = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save neural network structure\n",
    "model_structure = model.to_json()\n",
    "f = Path(\"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/SavedModel/model_structure.json\")\n",
    "f.write_text(model_structure)\n",
    "\n",
    "# Save neural network's trained weights\n",
    "model.save_weights(\"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/SavedModel/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1.]\n",
      "This is image is a glacier - Likelihood: 1.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from keras.models import model_from_json\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    " \n",
    "# Load the json file that contains the model's structure\n",
    "\n",
    "f = Path(\"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/SavedModel/model_structure.json\")\n",
    "model_structure = f.read_text()\n",
    "\n",
    "# Recreate the Keras model object from the json data\n",
    "model = model_from_json(model_structure)\n",
    "\n",
    "# Re-load the model's trained weights\n",
    "model.load_weights(\"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/SavedModel/model_weights.h5\")\n",
    "\n",
    "# Load an image file to test, resizing it to 32x32 pixels (as required by this model)\n",
    "\n",
    " \n",
    "# img = image.load_img(\"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/Data/seg_test/sea/20072.jpg\", target_size=(30, 30),color_mode=\"grayscale\")\n",
    "img = image.load_img(\"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/Data/seg_test/mountain/20157.jpg\", target_size=(30, 30),color_mode=\"grayscale\")\n",
    "# img = image.load_img(\"/home/celso/Documents/DeepLearning/ImageClassification/MiniProject/Data/seg_test/glacier/20059.jpg\", target_size=(30, 30),color_mode=\"grayscale\")\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "\n",
    "image_to_test = image.img_to_array(img)\n",
    "\n",
    "# Add a fourth dimension to the image (since Keras expects a list of images, not a single image)\n",
    "# list_of_images = np.expand_dims(y_test, axis=0)\n",
    "\n",
    "#predicting with an image from test set\n",
    "plt.imshow(x_test[1])\n",
    "\n",
    "# list_of_images = np.expand_dims(x_test[0], axis=0)\n",
    "list_of_images = np.expand_dims(image_to_test, axis=0)\n",
    "\n",
    "print(y_test[0])\n",
    "# Make a prediction using the model\n",
    "results = model.predict(list_of_images)\n",
    "\n",
    "# Since we are only testing one image, we only need to check the first result\n",
    "single_result = results[0]\n",
    "\n",
    "# We will get a likelihood score for all 10 possible classes. Find out which class had the highest score.\n",
    "most_likely_class_index = int(np.argmax(single_result))\n",
    "class_likelihood = single_result[most_likely_class_index]\n",
    "\n",
    "# Get the name of the most likely class\n",
    "class_label = class_labels[most_likely_class_index]\n",
    "\n",
    "# Print the result\n",
    "print(\"This is image is a {} - Likelihood: {:2f}\".format(class_label, class_likelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
